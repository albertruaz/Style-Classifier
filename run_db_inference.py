# run_db_inference.py

import torch
from torch.utils.data import DataLoader
from torchvision import transforms
import argparse
from tqdm import tqdm
import os

from model.morigirl_model import MoriGirlClassifier
from dataset.db_dataset import DBMorigirlInferenceDataset, save_morigirl_predictions_to_db

def create_inference_transform():
    """ì¶”ë¡ ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    return transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])

def load_model(checkpoint_path, device):
    """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
    model = MoriGirlClassifier()
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    return model

def run_batch_inference(model, dataloader, device, threshold=0.5):
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¶”ë¡  ìˆ˜í–‰"""
    predictions = {}
    
    model.eval()
    with torch.no_grad():
        for batch_idx, (images, product_ids) in enumerate(tqdm(dataloader, desc="ì¶”ë¡  ì¤‘")):
            images = images.to(device)
            
            # ëª¨ë¸ ì¶”ë¡ 
            logits = model(images)
            probs = torch.sigmoid(logits).cpu().numpy().flatten()
            
            # ê²°ê³¼ ì €ì¥
            for prob, product_id in zip(probs, product_ids):
                predictions[str(product_id.item())] = {
                    'is_morigirl': prob > threshold,
                    'confidence': float(prob)
                }
    
    return predictions

def main():
    parser = argparse.ArgumentParser(description='ë°ì´í„°ë² ì´ìŠ¤ ìƒí’ˆë“¤ì— ëŒ€í•œ ëª¨ë¦¬ê±¸ ë¶„ë¥˜ ì¶”ë¡ ')
    parser.add_argument('--checkpoint', required=True,
                       help='ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--threshold', type=float, default=0.5,
                       help='ë¶„ë¥˜ ì„ê³„ê°’')
    parser.add_argument('--where_condition', type=str, 
                       default="status = 'SALE' AND main_image IS NOT NULL",
                       help='ìƒí’ˆ í•„í„°ë§ ì¡°ê±´')
    parser.add_argument('--save_to_db', action='store_true',
                       help='ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í• ì§€ ì—¬ë¶€')
    parser.add_argument('--max_products', type=int, default=None,
                       help='ìµœëŒ€ ì²˜ë¦¬í•  ìƒí’ˆ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)')
    
    args = parser.parse_args()
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ë””ë°”ì´ìŠ¤: {device}")
    
    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í™•ì¸
    if not os.path.exists(args.checkpoint):
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.checkpoint}")
        return
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        print("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...")
        model = load_model(args.checkpoint, device)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ë°ì´í„°ì…‹ ìƒì„±
        print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìƒí’ˆ ë°ì´í„° ë¡œë”© ì¤‘...")
        transform = create_inference_transform()
        
        dataset = DBMorigirlInferenceDataset(
            where_condition=args.where_condition,
            transform=transform,
            batch_size=1000  # DBì—ì„œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¡œë“œ
        )
        
        # ìµœëŒ€ ìƒí’ˆ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
        if args.max_products:
            dataset.total_count = min(dataset.total_count, args.max_products)
        
        dataloader = DataLoader(
            dataset, 
            batch_size=args.batch_size, 
            shuffle=False,
            num_workers=4,
            pin_memory=True
        )
        
        print(f"ğŸ“ˆ ì¶”ë¡  ì‹œì‘ - ì´ {dataset.total_count:,}ê°œ ìƒí’ˆ")
        print(f"ğŸ”§ ì„¤ì •: ë°°ì¹˜í¬ê¸°={args.batch_size}, ì„ê³„ê°’={args.threshold}")
        
        # ì¶”ë¡  ìˆ˜í–‰
        all_predictions = {}
        batch_count = 0
        
        try:
            while True:
                try:
                    # í˜„ì¬ ë°°ì¹˜ ì¶”ë¡ 
                    predictions = run_batch_inference(model, dataloader, device, args.threshold)
                    all_predictions.update(predictions)
                    batch_count += 1
                    
                    # ì§„í–‰ ìƒí™© ì¶œë ¥
                    progress = dataset.get_progress()
                    print(f"ğŸ“Š ì§„í–‰ë¥ : {progress['progress_pct']:.1f}% "
                          f"({progress['processed']:,}/{progress['total']:,})")
                    
                    # ì¤‘ê°„ ì €ì¥ (1000ê°œë§ˆë‹¤)
                    if args.save_to_db and len(all_predictions) % 1000 == 0:
                        print("ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘...")
                        save_morigirl_predictions_to_db(predictions)
                        predictions.clear()  # ë©”ëª¨ë¦¬ ì ˆì•½
                    
                    # ë‹¤ìŒ ë°°ì¹˜ ë¡œë“œ
                    dataset._load_next_batch()
                    
                except StopIteration:
                    break
                    
        except KeyboardInterrupt:
            print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        
        # ìµœì¢… ê²°ê³¼ ì²˜ë¦¬
        print(f"\nâœ… ì¶”ë¡  ì™„ë£Œ - ì´ {len(all_predictions):,}ê°œ ìƒí’ˆ ì²˜ë¦¬")
        
        # ê²°ê³¼ ìš”ì•½
        morigirl_count = sum(1 for pred in all_predictions.values() if pred['is_morigirl'])
        avg_confidence = sum(pred['confidence'] for pred in all_predictions.values()) / len(all_predictions)
        
        print(f"ğŸ“Š ê²°ê³¼ ìš”ì•½:")
        print(f"  - ëª¨ë¦¬ê±¸ë¡œ ë¶„ë¥˜ëœ ìƒí’ˆ: {morigirl_count:,}ê°œ ({morigirl_count/len(all_predictions)*100:.1f}%)")
        print(f"  - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if args.save_to_db and all_predictions:
            print("ğŸ’¾ ìµœì¢… ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
            save_morigirl_predictions_to_db(all_predictions)
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ")
        
        # ìƒìœ„ ì‹ ë¢°ë„ ëª¨ë¦¬ê±¸ ìƒí’ˆë“¤ ì¶œë ¥
        morigirl_products = [(pid, pred) for pid, pred in all_predictions.items() 
                            if pred['is_morigirl']]
        morigirl_products.sort(key=lambda x: x[1]['confidence'], reverse=True)
        
        print(f"\nğŸ† ìƒìœ„ 10ê°œ ëª¨ë¦¬ê±¸ ìƒí’ˆ:")
        for i, (product_id, pred) in enumerate(morigirl_products[:10], 1):
            print(f"  {i}. ìƒí’ˆ ID: {product_id}, ì‹ ë¢°ë„: {pred['confidence']:.3f}")
        
    except Exception as e:
        print(f"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    
    finally:
        print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        if 'dataset' in locals():
            dataset.close()

if __name__ == "__main__":
    main() 