# inference_score_model.py

import torch
import numpy as np
import json
import os
from typing import List, Dict, Any, Tuple
import pandas as pd
from tqdm import tqdm

from dataset.product_score_dataset import ProductScoreDataset
from model.score_prediction_model import ProductScorePredictor
from database import DatabaseManager
from utils.train_utils import load_checkpoint

class ProductScoreInference:
    """ìƒí’ˆ ì ìˆ˜ ì¶”ë¡ ê¸°"""
    
    def __init__(self, 
                 model_path: str,
                 config_path: str = "./config.json",
                 device: str = None):
        """
        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cuda', 'cpu', None=ìë™)
        """
        # ì„¤ì • ë¡œë“œ
        with open(config_path, 'r') as f:
            self.config = json.load(f)
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        print(f"ğŸš€ ì¶”ë¡  ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model(model_path)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
        self.db_manager = DatabaseManager()
        
        print("âœ… ì¶”ë¡ ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_model(self, model_path: str) -> ProductScorePredictor:
        """ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        # ëª¨ë¸ ìƒì„±
        model_config = self.config['model']
        model = ProductScorePredictor(
            input_dim=model_config['input_vector_dim'] + 1,
            hidden_dim=model_config['hidden_dim'],
            dropout=model_config['dropout']
        )
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = load_checkpoint(model_path, self.device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        print(f"ğŸ“¦ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        print(f"  - ì—í­: {checkpoint.get('epoch', 'N/A')}")
        print(f"  - ê²€ì¦ ì†ì‹¤: {checkpoint.get('val_loss', 'N/A'):.4f}")
        
        return model
    
    def predict_single(self, 
                      image_vector: np.ndarray, 
                      price: float) -> Dict[str, float]:
        """
        ë‹¨ì¼ ìƒí’ˆ ì ìˆ˜ ì˜ˆì¸¡
        
        Args:
            image_vector: ì´ë¯¸ì§€ ì„ë² ë”© ë²¡í„° (1024,)
            price: ìƒí’ˆ ê°€ê²©
            
        Returns:
            dict: {'morigirl_prob': float, 'popularity_prob': float}
        """
        # ì…ë ¥ ì¤€ë¹„
        price_normalized = np.log(max(price, 1.0)) / 10.0
        input_vector = np.concatenate([image_vector, [price_normalized]])
        input_tensor = torch.FloatTensor(input_vector).unsqueeze(0).to(self.device)
        
        # ì˜ˆì¸¡
        with torch.no_grad():
            morigirl_prob, popularity_prob = self.model(input_tensor)
            
            return {
                'morigirl_prob': morigirl_prob.item(),
                'popularity_prob': popularity_prob.item()
            }
    
    def predict_batch(self, 
                     product_ids: List[int],
                     batch_size: int = 32) -> pd.DataFrame:
        """
        ë°°ì¹˜ ë‹¨ìœ„ ìƒí’ˆ ì ìˆ˜ ì˜ˆì¸¡
        
        Args:
            product_ids: ì˜ˆì¸¡í•  ìƒí’ˆ ID ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            DataFrame: ìƒí’ˆë³„ ì˜ˆì¸¡ ê²°ê³¼
        """
        results = []
        
        # ìƒí’ˆ ë°ì´í„° ì¡°íšŒ
        print("ğŸ“Š ìƒí’ˆ ë°ì´í„° ì¡°íšŒ ì¤‘...")
        product_data = self._get_product_data(product_ids)
        product_vectors = self._get_product_vectors(product_ids)
        
        # ë°°ì¹˜ë³„ ì˜ˆì¸¡
        print("ğŸ”® ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
        
        for i in tqdm(range(0, len(product_data), batch_size)):
            batch_data = product_data[i:i + batch_size]
            batch_inputs = []
            batch_results = []
            
            for product in batch_data:
                product_id = product['product_id']
                
                # ë²¡í„°ê°€ ì—†ëŠ” ìƒí’ˆ ê±´ë„ˆë›°ê¸°
                if product_id not in product_vectors:
                    continue
                
                # ì…ë ¥ ë²¡í„° ì¤€ë¹„
                image_vector = product_vectors[product_id]
                price = float(product['amount'])
                price_normalized = np.log(max(price, 1.0)) / 10.0
                
                input_vector = np.concatenate([image_vector, [price_normalized]])
                batch_inputs.append(input_vector)
                batch_results.append(product)
            
            if not batch_inputs:
                continue
            
            # ë°°ì¹˜ ì˜ˆì¸¡
            batch_tensor = torch.FloatTensor(np.array(batch_inputs)).to(self.device)
            
            with torch.no_grad():
                morigirl_probs, popularity_probs = self.model(batch_tensor)
                
                for j, product in enumerate(batch_results):
                    results.append({
                        'product_id': product['product_id'],
                        'morigirl_prob': morigirl_probs[j].item(),
                        'popularity_prob': popularity_probs[j].item(),
                        'price': product['amount'],
                        'status': product['status'],
                        'view': product.get('view', 0),
                        'impression': product.get('impression', 0)
                    })
        
        return pd.DataFrame(results)
    
    def _get_product_data(self, product_ids: List[int]) -> List[Dict[str, Any]]:
        """ìƒí’ˆ ê¸°ë³¸ ë°ì´í„° ì¡°íšŒ"""
        session = self.db_manager.mysql.Session()
        try:
            from sqlalchemy import text
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            batch_size = self.config['database']['mysql_batch_size']
            all_products = []
            
            for i in range(0, len(product_ids), batch_size):
                batch_ids = product_ids[i:i + batch_size]
                
                sql = text("""
                    SELECT 
                        id,
                        status,
                        views,
                        impressions,
                        amount
                    FROM vingle.product 
                    WHERE id IN :product_ids
                      AND amount IS NOT NULL
                """)
                
                result = session.execute(sql, {"product_ids": tuple(batch_ids)})
                
                for row in result.fetchall():
                    all_products.append({
                        'product_id': row[0],
                        'status': row[1],
                        'views': row[2] or 0,
                        'impressions': row[3] or 0,
                        'amount': row[4]
                    })
            
            return all_products
            
        finally:
            session.close()
    
    def _get_product_vectors(self, product_ids: List[int]) -> Dict[int, np.ndarray]:
        """ìƒí’ˆ ì„ë² ë”© ë²¡í„° ì¡°íšŒ"""
        session = self.db_manager.vector_db.Session()
        try:
            from sqlalchemy import text
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            batch_size = self.config['database']['vector_batch_size']
            all_vectors = {}
            
            for i in range(0, len(product_ids), batch_size):
                batch_ids = product_ids[i:i + batch_size]
                
                if not batch_ids:
                    continue
                
                # IN ì¿¼ë¦¬ìš© í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±
                placeholders = ','.join([':id' + str(j) for j in range(len(batch_ids))])
                sql = text(f"""
                    SELECT id, image_vector
                    FROM product_vectors
                    WHERE id IN ({placeholders})
                """)
                
                # íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
                params = {f'id{j}': batch_ids[j] for j in range(len(batch_ids))}
                result = session.execute(sql, params)
                
                for product_id, vector_str in result.fetchall():
                    if vector_str:
                        # PostgreSQL VECTOR í˜•ì‹ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
                        vector_str = vector_str.strip('[]')
                        vector = np.array([float(x) for x in vector_str.split(',')])
                        all_vectors[product_id] = vector
            
            return all_vectors
            
        finally:
            session.close()
    
    def predict_style_products(self, 
                              style_id: int = None,
                              limit: int = 1000) -> pd.DataFrame:
        """
        íŠ¹ì • ìŠ¤íƒ€ì¼ì˜ ëª¨ë“  ìƒí’ˆ ì˜ˆì¸¡
        
        Args:
            style_id: ìŠ¤íƒ€ì¼ ID (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
            limit: ì˜ˆì¸¡í•  ìµœëŒ€ ìƒí’ˆ ìˆ˜
            
        Returns:
            DataFrame: ì˜ˆì¸¡ ê²°ê³¼
        """
        if style_id is None:
            style_id = self.config['style_id']
        
        # ìŠ¤íƒ€ì¼ ìƒí’ˆ ì¡°íšŒ
        print(f"ğŸ¨ Style {style_id} ìƒí’ˆ ì¡°íšŒ ì¤‘...")
        product_ids = self._get_style_product_ids(style_id, limit)
        
        if not product_ids:
            print(f"âš ï¸ Style {style_id}ì— í•´ë‹¹í•˜ëŠ” ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        print(f"ğŸ“¦ {len(product_ids)}ê°œ ìƒí’ˆ ë°œê²¬")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        results_df = self.predict_batch(product_ids)
        
        # ê²°ê³¼ ì •ë ¬ (ëª¨ë¦¬ê±¸ í™•ë¥  ë†’ì€ ìˆœ)
        results_df = results_df.sort_values('morigirl_prob', ascending=False)
        
        return results_df
    
    def _get_style_product_ids(self, style_id: int, limit: int) -> List[int]:
        """íŠ¹ì • ìŠ¤íƒ€ì¼ì˜ ìƒí’ˆ ID ì¡°íšŒ"""
        session = self.db_manager.mysql.Session()
        try:
            from sqlalchemy import text
            
            sql = text("""
                SELECT DISTINCT ps.product_id 
                FROM vingle.product_styles AS ps
                JOIN vingle.product AS p ON ps.product_id = p.id
                WHERE ps.styles_id LIKE :style_id
                  AND p.status IN ('SALE', 'SOLD_OUT')
                  AND p.amount IS NOT NULL
                ORDER BY p.id DESC
                LIMIT :limit
            """)
            
            result = session.execute(sql, {
                "style_id": str(style_id),
                "limit": limit
            })
            
            return [row[0] for row in result.fetchall()]
            
        finally:
            session.close()
    
    def save_predictions(self, 
                        predictions_df: pd.DataFrame,
                        output_path: str):
        """ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
        predictions_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {output_path}")
    
    def update_database_predictions(self, 
                                   predictions_df: pd.DataFrame,
                                   table_name: str = 'product_morigirl_scores'):
        """ë°ì´í„°ë² ì´ìŠ¤ì— ì˜ˆì¸¡ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
        if predictions_df.empty:
            print("âš ï¸ ì—…ë°ì´íŠ¸í•  ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        session = self.db_manager.mysql.Session()
        try:
            from sqlalchemy import text
            
            # ë°°ì¹˜ ì—…ë°ì´íŠ¸
            print(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘... ({len(predictions_df)}ê°œ ìƒí’ˆ)")
            
            for _, row in tqdm(predictions_df.iterrows(), total=len(predictions_df)):
                sql = text(f"""
                    INSERT INTO vingle.{table_name} 
                    (product_id, morigirl_prob, popularity_prob, updated_at)
                    VALUES (:product_id, :morigirl_prob, :popularity_prob, NOW())
                    ON DUPLICATE KEY UPDATE
                    morigirl_prob = :morigirl_prob,
                    popularity_prob = :popularity_prob,
                    updated_at = NOW()
                """)
                
                session.execute(sql, {
                    'product_id': int(row['product_id']),
                    'morigirl_prob': float(row['morigirl_prob']),
                    'popularity_prob': float(row['popularity_prob'])
                })
            
            session.commit()
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            session.rollback()
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            raise
        finally:
            session.close()
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self, 'db_manager'):
            self.db_manager.dispose_all()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì„¤ì •
    model_path = "./checkpoints/best_model.pth"  # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    config_path = "./config.json"
    
    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        print("ë¨¼ì € train_score_model.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return
    
    try:
        # ì¶”ë¡ ê¸° ìƒì„±
        inferencer = ProductScoreInference(model_path, config_path)
        
        # íŠ¹ì • ìŠ¤íƒ€ì¼ ìƒí’ˆë“¤ì— ëŒ€í•œ ì˜ˆì¸¡
        print("ğŸ”® ëª¨ë¦¬ê±¸ ìŠ¤íƒ€ì¼ ìƒí’ˆ ì˜ˆì¸¡ ì¤‘...")
        predictions_df = inferencer.predict_style_products(limit=500)
        
        if not predictions_df.empty:
            # ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
            print(f"  - ì´ ì˜ˆì¸¡ ìƒí’ˆ: {len(predictions_df)}ê°œ")
            print(f"  - í‰ê·  ëª¨ë¦¬ê±¸ í™•ë¥ : {predictions_df['morigirl_prob'].mean():.3f}")
            print(f"  - í‰ê·  ì¸ê¸°ë„ í™•ë¥ : {predictions_df['popularity_prob'].mean():.3f}")
            print(f"  - ëª¨ë¦¬ê±¸ í™•ë¥  > 0.7: {(predictions_df['morigirl_prob'] > 0.7).sum()}ê°œ")
            print(f"  - ì¸ê¸°ë„ í™•ë¥  > 0.5: {(predictions_df['popularity_prob'] > 0.5).sum()}ê°œ")
            
            # ìƒìœ„ ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ† ìƒìœ„ 10ê°œ ëª¨ë¦¬ê±¸ ìƒí’ˆ:")
            top_morigirl = predictions_df.head(10)
            for _, row in top_morigirl.iterrows():
                print(f"  ìƒí’ˆ {row['product_id']}: ëª¨ë¦¬ê±¸={row['morigirl_prob']:.3f}, "
                      f"ì¸ê¸°ë„={row['popularity_prob']:.3f}, ê°€ê²©={row['price']:,}ì›")
            
            # ê²°ê³¼ ì €ì¥
            output_path = f"./predictions_morigirl_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
            inferencer.save_predictions(predictions_df, output_path)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ (ì„ íƒì‚¬í•­)
            update_db = input("\në°ì´í„°ë² ì´ìŠ¤ì— ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if update_db.lower() == 'y':
                inferencer.update_database_predictions(predictions_df)
        
        inferencer.close()
        
    except Exception as e:
        print(f"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 