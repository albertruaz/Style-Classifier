# train_score_model.py

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import json
import os
import time
from datetime import datetime
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import wandb
import os
from dotenv import load_dotenv

from dataset.product_score_dataset import ProductScoreDataset, create_train_test_datasets
from model.score_prediction_model import ProductScorePredictor, ProductScoreLoss, get_model_info
from utils.train_utils import EarlyStopping, save_checkpoint, load_checkpoint

class ScoreModelTrainer:
    """ìƒí’ˆ ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµê¸°"""
    
    def __init__(self, config_path: str = "./config.json"):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        # ì„¤ì • ë¡œë“œ
        with open(config_path, 'r') as f:
            self.config = json.load(f)
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = self._create_model()
        
        # ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
        self.criterion = ProductScoreLoss(
            morigirl_weight=1.0,
            popularity_weight=0.5  # ì¸ê¸°ë„ëŠ” ì¡°ê¸ˆ ë” ë‚®ì€ ê°€ì¤‘ì¹˜
        )
        
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=self.config['model']['learning_rate'],
            weight_decay=1e-4
        )
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5, patience=5, verbose=True
        )
        
        # Early stopping
        self.early_stopping = EarlyStopping(
            patience=10, min_delta=0.001, restore_best_weights=True
        )
        
        # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
        self.checkpoint_dir = "./checkpoints"
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        
        # WandB ì„¤ì •
        self.use_wandb = False
        self.wandb_run = None
        
        # í•™ìŠµ ê¸°ë¡
        self.train_history = {
            'train_loss': [], 'val_loss': [],
            'train_morigirl_acc': [], 'val_morigirl_acc': [],
            'train_popularity_mse': [], 'val_popularity_mse': []
        }
    
    def _create_model(self) -> ProductScorePredictor:
        """ëª¨ë¸ ìƒì„±"""
        model_config = self.config['model']
        
        model = ProductScorePredictor(
            input_dim=model_config['input_vector_dim'] + 1,  # +1 for price
            hidden_dim=model_config['hidden_dim'],
            dropout=model_config['dropout']
        ).to(self.device)
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        info = get_model_info(model)
        print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
        print(f"  - ì´ íŒŒë¼ë¯¸í„°: {info['total_params']:,}")
        print(f"  - ëª¨ë¸ í¬ê¸°: {info['model_size_mb']:.2f} MB")
        
        return model
    
    def _prepare_data(self):
        """ë°ì´í„°ì…‹ ì¤€ë¹„"""
        print("ğŸ“Š ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘...")
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
        train_dataset, val_dataset = create_train_test_datasets(self.config_path)
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        batch_size = self.config['model']['batch_size']
        
        self.train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True,
            num_workers=4,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        self.val_loader = DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
        print(f"  - í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(self.train_loader)}")
        print(f"  - ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(self.val_loader)}")
    
    def _train_epoch(self) -> dict:
        """í•œ ì—í­ í›ˆë ¨"""
        self.model.train()
        
        total_loss = 0
        morigirl_preds, morigirl_targets = [], []
        popularity_losses = []
        
        pbar = tqdm(self.train_loader, desc="Training")
        
        for inputs, targets in pbar:
            inputs = inputs.to(self.device)
            morigirl_target = targets[:, 0:1].to(self.device)
            popularity_target = targets[:, 1:2].to(self.device)
            
            # ìˆœì „íŒŒ
            morigirl_pred, popularity_pred = self.model(inputs)
            
            # ì†ì‹¤ ê³„ì‚°
            losses = self.criterion(
                morigirl_pred, popularity_pred,
                morigirl_target, popularity_target
            )
            
            # ì—­ì „íŒŒ
            self.optimizer.zero_grad()
            losses['total_loss'].backward()
            
            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            total_loss += losses['total_loss'].item()
            
            # ëª¨ë¦¬ê±¸ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
            morigirl_preds.extend((morigirl_pred > 0.5).cpu().numpy().flatten())
            morigirl_targets.extend(morigirl_target.cpu().numpy().flatten())
            
            # ì¸ê¸°ë„ MSE
            popularity_losses.append(losses['popularity_loss'].item())
            
            # ì§„í–‰ë°” ì—…ë°ì´íŠ¸
            pbar.set_postfix({
                'loss': f"{losses['total_loss'].item():.4f}",
                'mori_loss': f"{losses['morigirl_loss'].item():.4f}",
                'pop_loss': f"{losses['popularity_loss'].item():.4f}"
            })
        
        # ì—í­ ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_loss = total_loss / len(self.train_loader)
        morigirl_acc = accuracy_score(morigirl_targets, morigirl_preds)
        avg_popularity_mse = np.mean(popularity_losses)
        
        return {
            'loss': avg_loss,
            'morigirl_acc': morigirl_acc,
            'popularity_mse': avg_popularity_mse
        }
    
    def _validate_epoch(self) -> dict:
        """í•œ ì—í­ ê²€ì¦"""
        self.model.eval()
        
        total_loss = 0
        morigirl_preds, morigirl_targets = [], []
        popularity_losses = []
        
        with torch.no_grad():
            for inputs, targets in tqdm(self.val_loader, desc="Validation"):
                inputs = inputs.to(self.device)
                morigirl_target = targets[:, 0:1].to(self.device)
                popularity_target = targets[:, 1:2].to(self.device)
                
                # ìˆœì „íŒŒ
                morigirl_pred, popularity_pred = self.model(inputs)
                
                # ì†ì‹¤ ê³„ì‚°
                losses = self.criterion(
                    morigirl_pred, popularity_pred,
                    morigirl_target, popularity_target
                )
                
                total_loss += losses['total_loss'].item()
                
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                morigirl_preds.extend((morigirl_pred > 0.5).cpu().numpy().flatten())
                morigirl_targets.extend(morigirl_target.cpu().numpy().flatten())
                popularity_losses.append(losses['popularity_loss'].item())
        
        # ê²€ì¦ ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_loss = total_loss / len(self.val_loader)
        morigirl_acc = accuracy_score(morigirl_targets, morigirl_preds)
        avg_popularity_mse = np.mean(popularity_losses)
        
        return {
            'loss': avg_loss,
            'morigirl_acc': morigirl_acc,
            'popularity_mse': avg_popularity_mse
        }
    
    def train(self):
        """ëª¨ë¸ í•™ìŠµ"""
        print(f"ğŸš€ í•™ìŠµ ì‹œì‘ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ë°ì´í„° ì¤€ë¹„
        self._prepare_data()
        
        # WandB ì´ˆê¸°í™”
        self.use_wandb = self._initialize_wandb()
        
        num_epochs = self.config['model']['epochs']
        best_val_loss = float('inf')
        
        for epoch in range(num_epochs):
            start_time = time.time()
            
            print(f"\n=== Epoch {epoch+1}/{num_epochs} ===")
            
            # í›ˆë ¨
            train_metrics = self._train_epoch()
            
            # ê²€ì¦
            val_metrics = self._validate_epoch()
            
            # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
            self.scheduler.step(val_metrics['loss'])
            
            epoch_time = time.time() - start_time
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"í›ˆë ¨ - Loss: {train_metrics['loss']:.4f}, "
                  f"Mori Acc: {train_metrics['morigirl_acc']:.4f}, "
                  f"Pop MSE: {train_metrics['popularity_mse']:.4f}")
            print(f"ê²€ì¦ - Loss: {val_metrics['loss']:.4f}, "
                  f"Mori Acc: {val_metrics['morigirl_acc']:.4f}, "
                  f"Pop MSE: {val_metrics['popularity_mse']:.4f}")
            print(f"ì‹œê°„: {epoch_time:.1f}ì´ˆ, LR: {self.optimizer.param_groups[0]['lr']:.2e}")
            
            # ê¸°ë¡ ì €ì¥
            self.train_history['train_loss'].append(train_metrics['loss'])
            self.train_history['val_loss'].append(val_metrics['loss'])
            self.train_history['train_morigirl_acc'].append(train_metrics['morigirl_acc'])
            self.train_history['val_morigirl_acc'].append(val_metrics['morigirl_acc'])
            self.train_history['train_popularity_mse'].append(train_metrics['popularity_mse'])
            self.train_history['val_popularity_mse'].append(val_metrics['popularity_mse'])
            
            # WandB ë¡œê¹…
            self._log_to_wandb(epoch, train_metrics, val_metrics)
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if val_metrics['loss'] < best_val_loss:
                best_val_loss = val_metrics['loss']
                save_checkpoint(
                    self.model, self.optimizer, epoch + 1, val_metrics['loss'],
                    os.path.join(self.checkpoint_dir, 'best_model.pth')
                )
                print("ğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥")
            
            # Early stopping ì²´í¬
            if self.early_stopping(val_metrics['loss'], self.model):
                print(f"â¹ï¸ Early stopping at epoch {epoch + 1}")
                break
        
        print(f"âœ… í•™ìŠµ ì™„ë£Œ!")
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥
        final_path = os.path.join(self.checkpoint_dir, f'final_model_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pth')
        save_checkpoint(self.model, self.optimizer, epoch + 1, val_metrics['loss'], final_path)
        
        # í•™ìŠµ ê³¡ì„  ê·¸ë¦¬ê¸°
        self._plot_training_curves()
        
        # WandB ì•„í‹°íŒ©íŠ¸ ì €ì¥ ë° ì¢…ë£Œ
        if self.use_wandb:
            self._save_wandb_artifacts()
            wandb.finish()
            print("ğŸ¯ WandB ì‹¤í—˜ ì¢…ë£Œ")
    
    def _initialize_wandb(self) -> bool:
        """WandB ì´ˆê¸°í™”"""
        try:
            import os
            from dotenv import load_dotenv
            
            # .env íŒŒì¼ ë¡œë“œ
            load_dotenv()
            
            wandb_config = {
                **self.config,
                'model_architecture': 'ProductScorePredictor',
                'device': str(self.device),
                'total_parameters': sum(p.numel() for p in self.model.parameters()),
                'trainable_parameters': sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            }
            
            # WandB í”„ë¡œì íŠ¸ ì„¤ì •
            project_name = os.getenv('WANDB_PROJECT', 'mori-look-score-prediction')
            entity_name = os.getenv('WANDB_ENTITY', 'albertruaz')
            
            self.wandb_run = wandb.init(
                project=project_name,
                entity=entity_name,
                config=wandb_config,
                name=f"score_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                tags=['morigirl', 'popularity', 'multitask', 'score-prediction'],
                notes="ëª¨ë¦¬ê±¸ ìŠ¤íƒ€ì¼ ë¶„ë¥˜ì™€ ìƒí’ˆ ì¸ê¸°ë„ ì˜ˆì¸¡ì„ ìœ„í•œ ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸"
            )
            
            # ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œê¹…
            wandb.watch(self.model, log='all', log_freq=10)
            
            print("âœ… WandB ì´ˆê¸°í™” ì„±ê³µ")
            print(f"ğŸ“Š í”„ë¡œì íŠ¸: {project_name}")
            print(f"ğŸ‘¤ ì—”í‹°í‹°: {entity_name}")
            print(f"ğŸ”— ì‹¤í—˜ URL: {self.wandb_run.url}")
            
            return True
            
        except ImportError:
            print("âš ï¸ WandB ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("pip install wandb ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
            return False
        except Exception as e:
            print(f"âš ï¸ WandB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ë¡œì»¬ í•™ìŠµìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return False
    
    def _log_to_wandb(self, epoch: int, train_metrics: dict, val_metrics: dict):
        """WandBì— ë©”íŠ¸ë¦­ ë¡œê¹…"""
        if not self.use_wandb or not self.wandb_run:
            return
        
        try:
            # ë©”íŠ¸ë¦­ ë¡œê¹…
            wandb.log({
                'epoch': epoch + 1,
                
                # í›ˆë ¨ ë©”íŠ¸ë¦­
                'train/total_loss': train_metrics['loss'],
                'train/morigirl_accuracy': train_metrics['morigirl_acc'],
                'train/popularity_mse': train_metrics['popularity_mse'],
                
                # ê²€ì¦ ë©”íŠ¸ë¦­
                'val/total_loss': val_metrics['loss'],
                'val/morigirl_accuracy': val_metrics['morigirl_acc'],
                'val/popularity_mse': val_metrics['popularity_mse'],
                
                # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
                'system/learning_rate': self.optimizer.param_groups[0]['lr'],
                'system/epoch': epoch + 1
            })
            
            # ë§¤ 10 ì—í­ë§ˆë‹¤ ì¶”ê°€ ë¶„ì„
            if (epoch + 1) % 10 == 0:
                self._log_detailed_analysis(epoch, val_metrics)
                
        except Exception as e:
            print(f"âš ï¸ WandB ë¡œê¹… ì‹¤íŒ¨: {e}")
    
    def _log_detailed_analysis(self, epoch: int, val_metrics: dict):
        """ìƒì„¸ ë¶„ì„ ë¡œê¹…"""
        if not self.use_wandb or not self.wandb_run:
            return
        
        try:
            # ëª¨ë¸ ê°€ì¤‘ì¹˜ íˆìŠ¤í† ê·¸ë¨
            for name, param in self.model.named_parameters():
                if param.grad is not None:
                    wandb.log({
                        f"weights/{name}": wandb.Histogram(param.data.cpu().numpy()),
                        f"gradients/{name}": wandb.Histogram(param.grad.cpu().numpy())
                    })
            
            # ê²€ì¦ ë©”íŠ¸ë¦­ ìš”ì•½
            wandb.log({
                f"summary/val_loss_epoch_{epoch+1}": val_metrics['loss'],
                f"summary/val_morigirl_acc_epoch_{epoch+1}": val_metrics['morigirl_acc'],
                f"summary/val_popularity_mse_epoch_{epoch+1}": val_metrics['popularity_mse']
            })
            
        except Exception as e:
            print(f"âš ï¸ ìƒì„¸ ë¶„ì„ ë¡œê¹… ì‹¤íŒ¨: {e}")
    
    def _save_wandb_artifacts(self):
        """WandBì— ì•„í‹°íŒ©íŠ¸ ì €ì¥"""
        if not self.use_wandb or not self.wandb_run:
            return
        
        try:
            # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì•„í‹°íŒ©íŠ¸
            model_artifact = wandb.Artifact(
                name=f"mori_score_model",
                type="model",
                description="ëª¨ë¦¬ê±¸ ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸"
            )
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ íŒŒì¼ ì¶”ê°€
            best_model_path = os.path.join(self.checkpoint_dir, 'best_model.pth')
            if os.path.exists(best_model_path):
                model_artifact.add_file(best_model_path, name="best_model.pth")
            
            # ì„¤ì • íŒŒì¼ ì¶”ê°€
            if os.path.exists(self.config_path):
                model_artifact.add_file(self.config_path, name="config.json")
            
            # í•™ìŠµ ê³¡ì„  ì´ë¯¸ì§€ ì¶”ê°€
            training_curves_path = os.path.join(self.checkpoint_dir, 'training_curves.png')
            if os.path.exists(training_curves_path):
                model_artifact.add_file(training_curves_path, name="training_curves.png")
                # ì´ë¯¸ì§€ë¥¼ WandBì—ë„ ë¡œê¹…
                wandb.log({"training_curves": wandb.Image(training_curves_path)})
            
            # ì•„í‹°íŒ©íŠ¸ ë¡œê¹…
            self.wandb_run.log_artifact(model_artifact)
            
            print("ğŸ’¾ WandB ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ WandB ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _plot_training_curves(self):
        """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        epochs = range(1, len(self.train_history['train_loss']) + 1)
        
        # ì†ì‹¤ ê³¡ì„ 
        ax1.plot(epochs, self.train_history['train_loss'], 'b-', label='Train Loss')
        ax1.plot(epochs, self.train_history['val_loss'], 'r-', label='Val Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.set_xlabel('Epochs')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # ëª¨ë¦¬ê±¸ ì •í™•ë„
        ax2.plot(epochs, self.train_history['train_morigirl_acc'], 'b-', label='Train Acc')
        ax2.plot(epochs, self.train_history['val_morigirl_acc'], 'r-', label='Val Acc')
        ax2.set_title('Morigirl Classification Accuracy')
        ax2.set_xlabel('Epochs')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True)
        
        # ì¸ê¸°ë„ MSE
        ax3.plot(epochs, self.train_history['train_popularity_mse'], 'b-', label='Train MSE')
        ax3.plot(epochs, self.train_history['val_popularity_mse'], 'r-', label='Val MSE')
        ax3.set_title('Popularity Prediction MSE')
        ax3.set_xlabel('Epochs')
        ax3.set_ylabel('MSE')
        ax3.legend()
        ax3.grid(True)
        
        # í•™ìŠµë¥ 
        ax4.plot(epochs, [self.optimizer.param_groups[0]['lr']] * len(epochs), 'g-')
        ax4.set_title('Learning Rate')
        ax4.set_xlabel('Epochs')
        ax4.set_ylabel('Learning Rate')
        ax4.set_yscale('log')
        ax4.grid(True)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.checkpoint_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š í•™ìŠµ ê³¡ì„  ì €ì¥: {os.path.join(self.checkpoint_dir, 'training_curves.png')}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    config_path = "./config.json"
    
    # ì„¤ì • íŒŒì¼ í™•ì¸
    if not os.path.exists(config_path):
        print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        return
    
    try:
        # íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í•™ìŠµ
        trainer = ScoreModelTrainer(config_path)
        trainer.train()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 