# utils/visualization.py

import torch
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import seaborn as sns
from torchvision import transforms
import cv2
import os
from typing import List, Dict, Any
import pandas as pd

def denormalize_image(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    """ì •ê·œí™”ëœ ì´ë¯¸ì§€ í…ì„œë¥¼ ì›ë³¸ìœ¼ë¡œ ë³µì›"""
    mean = torch.tensor(mean).view(3, 1, 1)
    std = torch.tensor(std).view(3, 1, 1)
    return tensor * std + mean

def visualize_predictions(model, dataset, device, num_samples=8, save_path='prediction_samples.png'):
    """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
    model.eval()
    
    # ëœë¤ ìƒ˜í”Œ ì„ íƒ
    indices = np.random.choice(len(dataset), num_samples, replace=False)
    
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    axes = axes.ravel()
    
    with torch.no_grad():
        for i, idx in enumerate(indices):
            image, true_label = dataset[idx]
            
            # ì˜ˆì¸¡
            image_batch = image.unsqueeze(0).to(device)
            logit = model(image_batch)
            prob = torch.sigmoid(logit).item()
            pred_label = 1 if prob > 0.5 else 0
            
            # ì´ë¯¸ì§€ í‘œì‹œ
            img_display = denormalize_image(image)
            img_display = torch.clamp(img_display, 0, 1)
            img_display = img_display.permute(1, 2, 0).numpy()
            
            axes[i].imshow(img_display)
            axes[i].axis('off')
            
            # ì œëª© ì„¤ì •
            true_class = 'ëª¨ë¦¬ê±¸' if true_label == 1 else 'ì¼ë°˜'
            pred_class = 'ëª¨ë¦¬ê±¸' if pred_label == 1 else 'ì¼ë°˜'
            color = 'green' if true_label == pred_label else 'red'
            
            axes[i].set_title(
                f'ì‹¤ì œ: {true_class}\nì˜ˆì¸¡: {pred_class} ({prob:.3f})',
                color=color, fontsize=10
            )
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {save_path}")
    plt.show()

def visualize_class_distribution(dataset, save_path='class_distribution.png'):
    """í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”"""
    labels = [dataset.labels[i] for i in range(len(dataset))]
    classes = ['ì¼ë°˜', 'ëª¨ë¦¬ê±¸']
    
    unique, counts = np.unique(labels, return_counts=True)
    
    plt.figure(figsize=(8, 6))
    bars = plt.bar(classes, counts, color=['skyblue', 'lightcoral'])
    plt.title('í´ë˜ìŠ¤ ë¶„í¬', fontsize=16)
    plt.ylabel('ì´ë¯¸ì§€ ìˆ˜', fontsize=12)
    
    # ë§‰ëŒ€ ìœ„ì— ìˆ«ì í‘œì‹œ
    for bar, count in zip(bars, counts):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,
                str(count), ha='center', fontsize=12)
    
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… í´ë˜ìŠ¤ ë¶„í¬ ì €ì¥: {save_path}")
    plt.show()

def plot_confidence_distribution(model, dataset, device, save_path='confidence_distribution.png'):
    """ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„í¬ ì‹œê°í™”"""
    model.eval()
    
    confidences_correct = []
    confidences_wrong = []
    
    with torch.no_grad():
        for i in range(len(dataset)):
            image, true_label = dataset[i]
            image_batch = image.unsqueeze(0).to(device)
            
            logit = model(image_batch)
            prob = torch.sigmoid(logit).item()
            pred_label = 1 if prob > 0.5 else 0
            
            confidence = prob if pred_label == 1 else (1 - prob)
            
            if pred_label == true_label:
                confidences_correct.append(confidence)
            else:
                confidences_wrong.append(confidence)
    
    plt.figure(figsize=(10, 6))
    plt.hist(confidences_correct, bins=20, alpha=0.7, label='ì •ë‹µ', color='green')
    plt.hist(confidences_wrong, bins=20, alpha=0.7, label='ì˜¤ë‹µ', color='red')
    plt.xlabel('ì˜ˆì¸¡ ì‹ ë¢°ë„', fontsize=12)
    plt.ylabel('ë¹ˆë„', fontsize=12)
    plt.title('ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„í¬', fontsize=16)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ì‹ ë¢°ë„ ë¶„í¬ ì €ì¥: {save_path}")
    plt.show()

def plot_training_history(history: Dict[str, List], save_path='training_history.png'):
    """í•™ìŠµ íˆìŠ¤í† ë¦¬ ì‹œê°í™”"""
    epochs = range(1, len(history['train_loss']) + 1)
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # ì†ì‹¤ ê·¸ë˜í”„
    axes[0].plot(epochs, history['train_loss'], 'b-', label='Training Loss')
    if 'val_loss' in history:
        axes[0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss')
    axes[0].set_title('Model Loss')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].legend()
    axes[0].grid(True)
    
    # ì •í™•ë„ ê·¸ë˜í”„ (ìˆëŠ” ê²½ìš°)
    if 'train_acc' in history:
        axes[1].plot(epochs, history['train_acc'], 'b-', label='Training Accuracy')
        if 'val_acc' in history:
            axes[1].plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy')
        axes[1].set_title('Model Accuracy')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Accuracy')
        axes[1].legend()
        axes[1].grid(True)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… í•™ìŠµ íˆìŠ¤í† ë¦¬ ì €ì¥: {save_path}")
    plt.show()

def plot_score_distribution(predictions_df: pd.DataFrame, save_path='score_distribution.png'):
    """ì ìˆ˜ ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬ ì‹œê°í™”"""
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # ëª¨ë¦¬ê±¸ í™•ë¥  ë¶„í¬
    axes[0].hist(predictions_df['morigirl_prob'], bins=50, alpha=0.7, color='pink')
    axes[0].set_title('ëª¨ë¦¬ê±¸ í™•ë¥  ë¶„í¬')
    axes[0].set_xlabel('ëª¨ë¦¬ê±¸ í™•ë¥ ')
    axes[0].set_ylabel('ìƒí’ˆ ìˆ˜')
    axes[0].grid(True, alpha=0.3)
    
    # ì¸ê¸°ë„ í™•ë¥  ë¶„í¬
    axes[1].hist(predictions_df['popularity_prob'], bins=50, alpha=0.7, color='skyblue')
    axes[1].set_title('ì¸ê¸°ë„ í™•ë¥  ë¶„í¬')
    axes[1].set_xlabel('ì¸ê¸°ë„ í™•ë¥ ')
    axes[1].set_ylabel('ìƒí’ˆ ìˆ˜')
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ì ìˆ˜ ë¶„í¬ ì €ì¥: {save_path}")
    plt.show()

def generate_grad_cam(model, image_tensor, target_layer_name='features'):
    """Grad-CAMì„ ì‚¬ìš©í•œ ì£¼ëª© ì˜ì—­ ì‹œê°í™”"""
    model.eval()
    
    # ê·¸ë˜ë””ì–¸íŠ¸ ì €ì¥ìš© ë³€ìˆ˜
    gradients = []
    activations = []
    
    def backward_hook(module, grad_input, grad_output):
        gradients.append(grad_output[0])
    
    def forward_hook(module, input, output):
        activations.append(output)
    
    # í›… ë“±ë¡
    target_layer = model.backbone.features[-1]  # ë§ˆì§€ë§‰ conv layer
    backward_handle = target_layer.register_backward_hook(backward_hook)
    forward_handle = target_layer.register_forward_hook(forward_hook)
    
    try:
        # Forward pass
        output = model(image_tensor)
        
        # Backward pass
        output.backward()
        
        # Grad-CAM ê³„ì‚°
        gradient = gradients[0][0]  # (C, H, W)
        activation = activations[0][0]  # (C, H, W)
        
        weights = torch.mean(gradient, dim=(1, 2))  # (C,)
        grad_cam = torch.sum(weights.unsqueeze(1).unsqueeze(2) * activation, dim=0)
        grad_cam = torch.relu(grad_cam)
        grad_cam = grad_cam / torch.max(grad_cam)
        
        return grad_cam.detach().cpu().numpy()
        
    finally:
        # í›… ì œê±°
        backward_handle.remove()
        forward_handle.remove()

def visualize_grad_cam(model, dataset, device, num_samples=4, save_path='grad_cam_visualization.png'):
    """Grad-CAM ì‹œê°í™”"""
    model.eval()
    
    indices = np.random.choice(len(dataset), num_samples, replace=False)
    
    fig, axes = plt.subplots(2, num_samples, figsize=(4*num_samples, 8))
    
    for i, idx in enumerate(indices):
        image, label = dataset[idx]
        image_batch = image.unsqueeze(0).to(device)
        image_batch.requires_grad_()
        
        # ì›ë³¸ ì´ë¯¸ì§€
        img_display = denormalize_image(image)
        img_display = torch.clamp(img_display, 0, 1)
        img_display = img_display.permute(1, 2, 0).numpy()
        
        axes[0, i].imshow(img_display)
        axes[0, i].set_title(f'{"ëª¨ë¦¬ê±¸" if label == 1 else "ì¼ë°˜"}')
        axes[0, i].axis('off')
        
        # Grad-CAM
        grad_cam = generate_grad_cam(model, image_batch)
        grad_cam_resized = cv2.resize(grad_cam, (224, 224))
        
        # íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´
        heatmap = plt.cm.jet(grad_cam_resized)[:, :, :3]
        superimposed = heatmap * 0.4 + img_display * 0.6
        
        axes[1, i].imshow(superimposed)
        axes[1, i].set_title('ì£¼ëª© ì˜ì—­')
        axes[1, i].axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Grad-CAM ì‹œê°í™” ì €ì¥: {save_path}")
    plt.show()

class ModelVisualizer:
    """ëª¨ë¸ ì‹œê°í™” ë„êµ¬ í´ë˜ìŠ¤"""
    
    def __init__(self, model, device, save_dir='./results'):
        self.model = model
        self.device = device
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
    
    def analyze_predictions(self, dataset, num_samples=8):
        """ì˜ˆì¸¡ ê²°ê³¼ ì¢…í•© ë¶„ì„"""
        print("ğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        
        # ì˜ˆì¸¡ ìƒ˜í”Œ ì‹œê°í™”
        visualize_predictions(
            self.model, dataset, self.device, num_samples,
            save_path=os.path.join(self.save_dir, 'prediction_samples.png')
        )
        
        # í´ë˜ìŠ¤ ë¶„í¬
        visualize_class_distribution(
            dataset,
            save_path=os.path.join(self.save_dir, 'class_distribution.png')
        )
        
        # ì‹ ë¢°ë„ ë¶„í¬
        plot_confidence_distribution(
            self.model, dataset, self.device,
            save_path=os.path.join(self.save_dir, 'confidence_distribution.png')
        )
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {self.save_dir}") 