#!/usr/bin/env python3
# train_model.py

import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
from datetime import datetime
import wandb  # í•™ìŠµ ëª¨ë‹ˆí„°ë§ìš© (ì„ íƒì‚¬í•­)
from tqdm import tqdm
from typing import Dict, Tuple, List
import argparse

# ë¡œì»¬ ëª¨ë“ˆ
from database import DatabaseManager
from dataset.morigirl_dataset import MorigirlDataset
from dataset.product_score_dataset import ProductScoreDataset
from model.morigirl_model import MorigirlModel
from model.score_prediction_model import ScorePredictionModel
from utils.train_utils import EarlyStopping, compute_metrics, save_checkpoint, load_checkpoint

class ModelTrainer:
    """ëª¨ë¸ í•™ìŠµ í´ëž˜ìŠ¤"""
    
    def __init__(self, config_path: str = "./config.json"):
        with open(config_path, 'r') as f:
            self.config = json.load(f)
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"âœ… í•™ìŠµ í™˜ê²½: {self.device}")
        
        # ì‹¤í—˜ ID ìƒì„±
        self.experiment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
        self.checkpoint_dir = f"./checkpoints/{self.experiment_id}"
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        
        print(f"ðŸ“ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬: {self.checkpoint_dir}")

    def setup_datasets(self, task_type: str, train_ratio: float = 0.8) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """ë°ì´í„°ì…‹ ì„¤ì •"""
        print(f"ðŸ“Š ë°ì´í„°ì…‹ ì„¤ì • ì¤‘... (Task: {task_type})")
        
        if task_type == "morigirl":
            # ëª¨ë¦¬ê±¸ ë¶„ë¥˜ ë°ì´í„°ì…‹
            dataset = MorigirlDataset(
                config=self.config,
                mode="train"
            )
            
            # í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• 
            total_size = len(dataset)
            train_size = int(total_size * train_ratio)
            val_size = int(total_size * 0.1)  # 10% ê²€ì¦
            test_size = total_size - train_size - val_size
            
            train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
                dataset, [train_size, val_size, test_size]
            )
            
        elif task_type == "score":
            # ì¸ê¸°ë„ ì ìˆ˜ ì˜ˆì¸¡ ë°ì´í„°ì…‹
            dataset = ProductScoreDataset(
                config=self.config,
                mode="train"
            )
            
            # í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• 
            total_size = len(dataset)
            train_size = int(total_size * train_ratio)
            val_size = int(total_size * 0.1)
            test_size = total_size - train_size - val_size
            
            train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
                dataset, [train_size, val_size, test_size]
            )
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒœìŠ¤í¬ íƒ€ìž…: {task_type}")
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        batch_size = self.config.get('training', {}).get('batch_size', 32)
        
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True, 
            num_workers=4,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        val_loader = DataLoader(
            val_dataset, 
            batch_size=batch_size, 
            shuffle=False, 
            num_workers=4,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        test_loader = DataLoader(
            test_dataset, 
            batch_size=batch_size, 
            shuffle=False, 
            num_workers=4,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        print(f"âœ… ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ:")
        print(f"  - í•™ìŠµ: {len(train_dataset):,}ê°œ")
        print(f"  - ê²€ì¦: {len(val_dataset):,}ê°œ")
        print(f"  - í…ŒìŠ¤íŠ¸: {len(test_dataset):,}ê°œ")
        
        return train_loader, val_loader, test_loader

    def setup_model(self, task_type: str) -> nn.Module:
        """ëª¨ë¸ ì„¤ì •"""
        print(f"ðŸ§  ëª¨ë¸ ì„¤ì • ì¤‘... (Task: {task_type})")
        
        if task_type == "morigirl":
            model = MorigirlModel(
                input_dim=1024,  # ì´ë¯¸ì§€ ë²¡í„° ì°¨ì›
                hidden_dim=self.config.get('model', {}).get('hidden_dim', 512),
                num_classes=2,   # ëª¨ë¦¬ê±¸ vs ì¼ë°˜
                dropout_rate=self.config.get('model', {}).get('dropout_rate', 0.3)
            )
        elif task_type == "score":
            model = ScorePredictionModel(
                image_dim=1024,
                hidden_dim=self.config.get('model', {}).get('hidden_dim', 512),
                dropout_rate=self.config.get('model', {}).get('dropout_rate', 0.3)
            )
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒœìŠ¤í¬ íƒ€ìž…: {task_type}")
        
        model.to(self.device)
        
        # ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ:")
        print(f"  - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
        print(f"  - í•™ìŠµ íŒŒë¼ë¯¸í„°: {trainable_params:,}ê°œ")
        
        return model

    def train_epoch(self, model: nn.Module, train_loader: DataLoader, 
                   criterion: nn.Module, optimizer: optim.Optimizer, 
                   task_type: str) -> Dict[str, float]:
        """í•œ ì—í¬í¬ í•™ìŠµ"""
        model.train()
        total_loss = 0.0
        correct_predictions = 0
        total_predictions = 0
        
        progress_bar = tqdm(train_loader, desc="í•™ìŠµ ì¤‘")
        
        for batch_idx, batch in enumerate(progress_bar):
            if task_type == "morigirl":
                image_vectors, labels = batch
                image_vectors = image_vectors.to(self.device)
                labels = labels.to(self.device)
                
                # Forward pass
                outputs = model(image_vectors)
                loss = criterion(outputs, labels)
                
                # ì •í™•ë„ ê³„ì‚°
                _, predicted = torch.max(outputs.data, 1)
                correct_predictions += (predicted == labels).sum().item()
                
            elif task_type == "score":
                image_vectors, scores = batch
                image_vectors = image_vectors.to(self.device)
                scores = scores.to(self.device)
                
                # Forward pass
                outputs = model(image_vectors)
                loss = criterion(outputs.squeeze(), scores)
            
            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            
            # Gradient clipping (ì„ íƒì‚¬í•­)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            total_predictions += labels.size(0) if task_type == "morigirl" else scores.size(0)
            
            # Progress bar ì—…ë°ì´íŠ¸
            avg_loss = total_loss / (batch_idx + 1)
            if task_type == "morigirl":
                accuracy = correct_predictions / total_predictions
                progress_bar.set_postfix({
                    'Loss': f'{avg_loss:.4f}',
                    'Acc': f'{accuracy:.4f}'
                })
            else:
                progress_bar.set_postfix({'Loss': f'{avg_loss:.4f}'})
        
        metrics = {'train_loss': total_loss / len(train_loader)}
        if task_type == "morigirl":
            metrics['train_accuracy'] = correct_predictions / total_predictions
        
        return metrics

    def validate_epoch(self, model: nn.Module, val_loader: DataLoader, 
                      criterion: nn.Module, task_type: str) -> Dict[str, float]:
        """í•œ ì—í¬í¬ ê²€ì¦"""
        model.eval()
        total_loss = 0.0
        correct_predictions = 0
        total_predictions = 0
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="ê²€ì¦ ì¤‘"):
                if task_type == "morigirl":
                    image_vectors, labels = batch
                    image_vectors = image_vectors.to(self.device)
                    labels = labels.to(self.device)
                    
                    outputs = model(image_vectors)
                    loss = criterion(outputs, labels)
                    
                    _, predicted = torch.max(outputs.data, 1)
                    correct_predictions += (predicted == labels).sum().item()
                    
                elif task_type == "score":
                    image_vectors, scores = batch
                    image_vectors = image_vectors.to(self.device)
                    scores = scores.to(self.device)
                    
                    outputs = model(image_vectors)
                    loss = criterion(outputs.squeeze(), scores)
                
                total_loss += loss.item()
                total_predictions += labels.size(0) if task_type == "morigirl" else scores.size(0)
        
        metrics = {'val_loss': total_loss / len(val_loader)}
        if task_type == "morigirl":
            metrics['val_accuracy'] = correct_predictions / total_predictions
        
        return metrics

    def train_model(self, task_type: str, epochs: int = 100, use_wandb: bool = False):
        """ëª¨ë¸ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜"""
        print(f"ðŸš€ ëª¨ë¸ í•™ìŠµ ì‹œìž‘ (Task: {task_type})")
        
        # WandB ì´ˆê¸°í™” (ì„ íƒì‚¬í•­)
        if use_wandb:
            wandb.init(
                project="mori-look",
                name=f"{task_type}_{self.experiment_id}",
                config=self.config
            )
        
        # ë°ì´í„°ì…‹ ì„¤ì •
        train_loader, val_loader, test_loader = self.setup_datasets(task_type)
        
        # ëª¨ë¸ ì„¤ì •
        model = self.setup_model(task_type)
        
        # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        if task_type == "morigirl":
            criterion = nn.CrossEntropyLoss()
            monitor_metric = 'val_accuracy'
            mode = 'max'
        else:  # score
            criterion = nn.MSELoss()
            monitor_metric = 'val_loss'
            mode = 'min'
        
        optimizer = optim.AdamW(
            model.parameters(),
            lr=self.config.get('training', {}).get('learning_rate', 1e-3),
            weight_decay=self.config.get('training', {}).get('weight_decay', 1e-4)
        )
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode=mode, factor=0.5, patience=5, verbose=True
        )
        
        # Early Stopping
        early_stopping = EarlyStopping(
            patience=10,
            mode=mode,
            min_delta=1e-4
        )
        
        # í•™ìŠµ ë£¨í”„
        best_metric = float('-inf') if mode == 'max' else float('inf')
        
        for epoch in range(epochs):
            print(f"\nðŸ“… Epoch {epoch+1}/{epochs}")
            
            # í•™ìŠµ
            train_metrics = self.train_epoch(model, train_loader, criterion, optimizer, task_type)
            
            # ê²€ì¦
            val_metrics = self.validate_epoch(model, val_loader, criterion, task_type)
            
            # ë©”íŠ¸ë¦­ ì¶œë ¥
            print(f"í•™ìŠµ ì†ì‹¤: {train_metrics['train_loss']:.4f}")
            print(f"ê²€ì¦ ì†ì‹¤: {val_metrics['val_loss']:.4f}")
            
            if task_type == "morigirl":
                print(f"í•™ìŠµ ì •í™•ë„: {train_metrics['train_accuracy']:.4f}")
                print(f"ê²€ì¦ ì •í™•ë„: {val_metrics['val_accuracy']:.4f}")
            
            # WandB ë¡œê¹…
            if use_wandb:
                wandb.log({
                    'epoch': epoch + 1,
                    **train_metrics,
                    **val_metrics,
                    'learning_rate': optimizer.param_groups[0]['lr']
                })
            
            # í•™ìŠµë¥  ì¡°ì •
            scheduler.step(val_metrics[monitor_metric])
            
            # ëª¨ë¸ ì €ìž¥ (ìµœê³  ì„±ëŠ¥)
            current_metric = val_metrics[monitor_metric]
            is_best = (mode == 'max' and current_metric > best_metric) or \
                     (mode == 'min' and current_metric < best_metric)
            
            if is_best:
                best_metric = current_metric
                save_checkpoint({
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'best_metric': best_metric,
                    'config': self.config
                }, os.path.join(self.checkpoint_dir, 'best_model.pth'))
                
                print(f"âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ìž¥! ({monitor_metric}: {best_metric:.4f})")
            
            # Early Stopping ì²´í¬
            if early_stopping(val_metrics[monitor_metric]):
                print(f"â¹ï¸ Early Stopping ë°œë™! (Epoch {epoch+1})")
                break
        
        # í…ŒìŠ¤íŠ¸ í‰ê°€
        print(f"\nðŸŽ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€")
        checkpoint = load_checkpoint(os.path.join(self.checkpoint_dir, 'best_model.pth'))
        model.load_state_dict(checkpoint['model_state_dict'])
        
        test_metrics = self.validate_epoch(model, test_loader, criterion, task_type)
        
        print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        for key, value in test_metrics.items():
            print(f"  - {key}: {value:.4f}")
        
        if use_wandb:
            wandb.log(test_metrics)
            wandb.finish()
        
        print(f"ðŸŽ‰ í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì €ìž¥ ìœ„ì¹˜: {self.checkpoint_dir}")
        
        return model, test_metrics

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ëª¨ë¸ í•™ìŠµ')
    parser.add_argument('--task', choices=['morigirl', 'score'], required=True, 
                       help='í•™ìŠµí•  íƒœìŠ¤í¬ (morigirl: ë¶„ë¥˜, score: ì ìˆ˜ ì˜ˆì¸¡)')
    parser.add_argument('--epochs', type=int, default=100, help='í•™ìŠµ ì—í¬í¬ ìˆ˜')
    parser.add_argument('--config', type=str, default='./config.json', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--use-wandb', action='store_true', help='WandB ì‚¬ìš© ì—¬ë¶€')
    
    args = parser.parse_args()
    
    try:
        trainer = ModelTrainer(args.config)
        model, metrics = trainer.train_model(
            task_type=args.task,
            epochs=args.epochs,
            use_wandb=args.use_wandb
        )
        
        print(f"\nâœ… í•™ìŠµ ì„±ê³µ!")
        print(f"ìµœì¢… ì„±ëŠ¥: {metrics}")
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main() 